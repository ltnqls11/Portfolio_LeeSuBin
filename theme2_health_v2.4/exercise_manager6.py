# êµ¬ê¸€ì‹œíŠ¸ë¡œ ê´€ë¦¬/dbì €ì¥ë¼ì„œ ë‚˜ì˜¤ë„ë¡
# exercise_manager_updated.py

import streamlit as st
import pandas as pd
from datetime import date, datetime, timedelta
import random
import altair as alt
import os
import json
from dotenv import load_dotenv

# YouTube ë°ì´í„° ì¡°íšŒë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
try:
    from youtube_collector import search_youtube_videos, search_videos_by_condition, collect_all_vdt_videos
    from database import get_videos_for_condition, get_recommended_videos_for_user, get_database_analytics
    from video_analyzer import analyze_single_video
    YOUTUBE_SEARCH_AVAILABLE = True
except ImportError as e:
    YOUTUBE_SEARCH_AVAILABLE = False

# Supabase ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
try:
    from supabase import create_client, Client
    from config import SUPABASE_URL, SUPABASE_ANON_KEY
    SUPABASE_AVAILABLE = True
    if SUPABASE_URL and SUPABASE_ANON_KEY:
        supabase: Client = create_client(SUPABASE_URL, SUPABASE_ANON_KEY)
    else:
        SUPABASE_AVAILABLE = False
except ImportError as e:
    SUPABASE_AVAILABLE = False

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Google Sheets ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GSPREAD_AVAILABLE = True
except ImportError:
    GSPREAD_AVAILABLE = False
    st.warning("Google Sheets ì—°ë™ì„ ì‚¬ìš©í•˜ë ¤ë©´ 'pip install -r requirements.txt'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

# --- Google Sheets ì„¤ì • ---
GOOGLE_SHEETS_CREDENTIALS = "credentials.json"
SPREADSHEET_ID = os.getenv("SPREADSHEET_ID", "")

def ensure_exercise_table_exists():
    """exercise_management í…Œì´ë¸” ì¡´ì¬ í™•ì¸ (ìƒì„±ì€ Supabase Dashboardì—ì„œ)"""
    if not SUPABASE_AVAILABLE:
        return False
    
    try:
        # í…Œì´ë¸” ì¡´ì¬ ì—¬ë¶€ í™•ì¸ - ê°„ë‹¨í•œ SELECT ì¿¼ë¦¬ë¡œ í…ŒìŠ¤íŠ¸
        result = supabase.table('exercise_management').select('id').limit(1).execute()
        return True
    except Exception as e:
        # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ì•ˆë‚´ ë©”ì‹œì§€
        st.warning("""
        âš ï¸ Supabaseì— 'exercise_management' í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.
        
        ë‹¤ìŒ SQLì„ Supabase Dashboardì—ì„œ ì‹¤í–‰í•´ì£¼ì„¸ìš”:
        ```sql
        CREATE TABLE IF NOT EXISTS exercise_management (
            id UUID DEFAULT gen_random_uuid() PRIMARY KEY,
            data_type VARCHAR(50) NOT NULL,
            user_email VARCHAR(255) NOT NULL,
            date DATE NOT NULL,
            value TEXT NOT NULL,
            details JSONB,
            created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
        );
        ```
        """)
        return False

def save_to_supabase(data_type, user_id, date, value):
    """Supabaseì— ë°ì´í„° ì €ì¥"""
    if not SUPABASE_AVAILABLE:
        return False
    
    try:
        # exercise_management í…Œì´ë¸”ì— ì €ì¥ ì‹œë„
        data = {
            'data_type': data_type,
            'user_email': user_id,
            'date': str(date),
            'value': str(value),
            'details': json.dumps({
                'timestamp': datetime.now().isoformat(),
                'type': data_type
            })
        }
        
        # ë¨¼ì € í…Œì´ë¸”ì´ ìˆëŠ”ì§€ í™•ì¸
        try:
            result = supabase.table('exercise_management').insert(data).execute()
            return True
        except Exception as table_error:
            # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ customer_history ì‚¬ìš©
            if 'PGRST' in str(table_error):
                st.info("ğŸ“ customer_history í…Œì´ë¸”ì„ ì‚¬ìš©í•©ë‹ˆë‹¤...")
                
                # customer_history í…Œì´ë¸” êµ¬ì¡°ì— ë§ê²Œ ì €ì¥
                history_data = {
                    'email': user_id,
                    'user_data': json.dumps({
                        'exercise_data': {
                            'data_type': data_type,
                            'date': str(date),
                            'value': str(value)
                        }
                    }),
                    'conditions': json.dumps([data_type]),
                    'pain_scores': json.dumps({'value': str(value)}) if data_type == 'pain_data' else json.dumps({}),
                    'created_at': datetime.now().isoformat()
                }
                
                result = supabase.table('customer_history').insert(history_data).execute()
                return True
            else:
                raise table_error
                
    except Exception as e:
        st.warning(f"Supabase ì €ì¥ ì˜¤ë¥˜: {e}")
        return False

def load_from_supabase(user_id=None):
    """Supabaseì—ì„œ ë°ì´í„° ë¡œë“œ"""
    if not SUPABASE_AVAILABLE:
        return pd.DataFrame(), pd.DataFrame()
    
    exercise_df = pd.DataFrame()
    pain_df = pd.DataFrame()
    
    # 1. exercise_management í…Œì´ë¸”ì—ì„œ ë¡œë“œ ì‹œë„
    try:
        query = supabase.table('exercise_management').select('*')
        if user_id:
            query = query.eq('user_email', user_id)
        
        result = query.execute()
        
        if result.data:
            df = pd.DataFrame(result.data)
            
            # ìš´ë™ ë°ì´í„° í•„í„°ë§
            exercise_data = df[df['data_type'] == 'exercise_log'].copy()
            if not exercise_data.empty:
                temp_df = exercise_data.copy()
                temp_df['user_id'] = temp_df['user_email'] if 'user_email' in temp_df.columns else user_id
                temp_df['date'] = pd.to_datetime(temp_df['date'])
                temp_df['completed_count'] = pd.to_numeric(temp_df['value'], errors='coerce').fillna(0)
                exercise_df = temp_df[['user_id', 'date', 'completed_count']].copy()
            
            # í†µì¦ ë°ì´í„° í•„í„°ë§  
            pain_data = df[df['data_type'] == 'pain_data'].copy()
            if not pain_data.empty:
                temp_df = pain_data.copy()
                temp_df['user_id'] = temp_df['user_email'] if 'user_email' in temp_df.columns else user_id
                temp_df['date'] = pd.to_datetime(temp_df['date'])
                temp_df['pain_level'] = pd.to_numeric(temp_df['value'], errors='coerce').fillna(0)
                pain_df = temp_df[['user_id', 'date', 'pain_level']].copy()
                
    except Exception as e:
        # exercise_management í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ customer_history ì‚¬ìš©
        pass
    
    # 2. customer_history í…Œì´ë¸”ì—ì„œë„ ë¡œë“œ ì‹œë„
    try:
        query = supabase.table('customer_history').select('*')
        if user_id:
            query = query.eq('email', user_id)
        
        result = query.execute()
        
        if result.data:
            for record in result.data:
                try:
                    user_data_str = record.get('user_data', '{}')
                    if isinstance(user_data_str, str):
                        user_data = json.loads(user_data_str)
                    else:
                        user_data = user_data_str
                    
                    # exercise_data í™•ì¸
                    if 'exercise_data' in user_data:
                        ex_data = user_data['exercise_data']
                        if ex_data.get('data_type') == 'exercise_log':
                            new_row = pd.DataFrame({
                                'user_id': [record.get('email', user_id)],
                                'date': [pd.to_datetime(ex_data.get('date'))],
                                'completed_count': [pd.to_numeric(ex_data.get('value', 0), errors='coerce')]
                            })
                            exercise_df = pd.concat([exercise_df, new_row], ignore_index=True)
                        elif ex_data.get('data_type') == 'pain_data':
                            new_row = pd.DataFrame({
                                'user_id': [record.get('email', user_id)],
                                'date': [pd.to_datetime(ex_data.get('date'))],
                                'pain_level': [pd.to_numeric(ex_data.get('value', 0), errors='coerce')]
                            })
                            pain_df = pd.concat([pain_df, new_row], ignore_index=True)
                            
                except Exception as parse_error:
                    continue
    except Exception as e:
        pass
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    if not exercise_df.empty:
        exercise_df = exercise_df.drop_duplicates(subset=['date'], keep='last').sort_values('date')
    if not pain_df.empty:
        pain_df = pain_df.drop_duplicates(subset=['date'], keep='last').sort_values('date')
    
    return exercise_df, pain_df

def init_google_sheets():
    """Google Sheets ì´ˆê¸°í™”"""
    try:
        if not GSPREAD_AVAILABLE or not os.path.exists(GOOGLE_SHEETS_CREDENTIALS):
            return None
            
        scope = [
            "https://www.googleapis.com/auth/spreadsheets",
            "https://www.googleapis.com/auth/drive"
        ]
        
        creds = Credentials.from_service_account_file(
            GOOGLE_SHEETS_CREDENTIALS, 
            scopes=scope
        )
        client = gspread.authorize(creds)
        return client
    except Exception as e:
        return None

def save_to_local_json(data, data_type, user_id):
    """ë°ì´í„°ë¥¼ ë¡œì»¬ JSON íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤. (í•˜ë£¨ì— í•œ ë²ˆë§Œ ê¸°ë¡, ì¤‘ë³µì‹œ ë®ì–´ì“°ê¸°)"""
    try:
        json_file = "local_exercise_data.json"
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ
        existing_data = []
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    existing_data = json.load(f)
            except Exception:
                existing_data = []
        
        # ì˜¤ëŠ˜ ë‚ ì§œ
        today = str(date.today())
        
        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ê°™ì€ íƒ€ì… ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì œê±° (í•˜ë£¨ì— í•œ ë²ˆë§Œ ê¸°ë¡)
        
        # ìƒˆ ë°ì´í„° ì¶”ê°€
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        new_record = {
            'timestamp': timestamp,
            'user_id': user_id,
            'data_type': data_type,
            'date': today,
            'value': data
        }
        
        existing_data.append(new_record)
        
        # JSON íŒŒì¼ì— ì €ì¥
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(existing_data, f, ensure_ascii=False, indent=2)
        
        st.success(f"{data_type} ë°ì´í„°ê°€ ë¡œì»¬ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        st.error(f"ë¡œì»¬ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return False

def save_to_google_sheets(data, sheet_name, user_id):
    """ë°ì´í„°ë¥¼ Google Sheetsì— ì €ì¥ (í•˜ë£¨ì— í•œ ë²ˆë§Œ ê¸°ë¡, ì¤‘ë³µì‹œ ë®ì–´ì“°ê¸°)"""
    try:
        if not GSPREAD_AVAILABLE or not os.path.exists(GOOGLE_SHEETS_CREDENTIALS):
            st.warning("Google Sheets ì—°ë™ì´ ë¹„í™œì„±í™”ë˜ì–´ ë¡œì»¬ì—ë§Œ ì €ì¥ë©ë‹ˆë‹¤.")
            return save_to_local_json(data, sheet_name, user_id)

        if not user_id:
            user_id = st.session_state.get('user_id', 'unknown_user')

        client = init_google_sheets()
        if not client:
            st.error("Google Sheets í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨.")
            return save_to_local_json(data, sheet_name, user_id)

        spreadsheet = client.open_by_key(SPREADSHEET_ID)
        
        # ì‹œíŠ¸ê°€ ì—†ìœ¼ë©´ ìƒì„±
        try:
            worksheet = spreadsheet.worksheet(sheet_name)
        except gspread.WorksheetNotFound:
            worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=10)
        
        # ì˜¤ëŠ˜ ë‚ ì§œ
        today = date.today().strftime("%Y-%m-%d")
        
        # ê¸°ì¡´ ë°ì´í„° í™•ì¸ (ì˜¤ëŠ˜ ë‚ ì§œì˜ ë°ì´í„°ê°€ ìˆëŠ”ì§€)
        try:
            all_records = worksheet.get_all_records()
            if all_records:
                df = pd.DataFrame(all_records)
                # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ timestamp, ë‘ ë²ˆì§¸ê°€ user_id
                df['date'] = pd.to_datetime(df.iloc[:, 0]).dt.date.astype(str)
                
                        # ì˜¤ëŠ˜ ë‚ ì§œì˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸ (í•˜ë£¨ì— í•œ ë²ˆë§Œ ê¸°ë¡)
        except Exception as e:
            st.warning(f"ê¸°ì¡´ ë°ì´í„° í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
        row_data = [datetime.now().strftime("%Y-%m-%d %H:%M:%S"), user_id, data]
        worksheet.append_row(row_data)
        
        st.success(f"{sheet_name} ë°ì´í„°ê°€ Google Sheetsì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True

    except gspread.exceptions.APIError as e:
        if "10000000" in str(e):
            st.warning("Google Sheets ì…€ í•œë„ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ë¡œì»¬ íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.")
            return save_to_local_json(data, sheet_name, user_id)
        else:
            st.error(f"Google Sheets API ì˜¤ë¥˜: {e}")
            return save_to_local_json(data, sheet_name, user_id)
    except Exception as e:
        st.error(f"Google Sheets ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")
        st.info("ë¡œì»¬ íŒŒì¼ì— ì €ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤.")
        return save_to_local_json(data, sheet_name, user_id)

# Google Sheets ì—°ê²° ìƒíƒœ í™•ì¸
try:
    client = init_google_sheets()
    if client and SPREADSHEET_ID:
        GOOGLE_SHEETS_ENABLED = True
    else:
        GOOGLE_SHEETS_ENABLED = False
except Exception as e:
    GOOGLE_SHEETS_ENABLED = False

# VDT ì¦í›„êµ° ì¦ìƒ ë°ì´í„° (app.pyì™€ ë™ì¼í•œ êµ¬ì¡°)
VDT_SYMPTOMS = {
    "ê±°ë¶ëª©": {
        "ì¦ìƒ": ["ëª© í†µì¦", "ì–´ê¹¨ ê²°ë¦¼", "ë‘í†µ", "íŒ” ì €ë¦¼"],
        "ì›ì¸": ["ì˜ëª»ëœ ìì„¸", "ì¥ì‹œê°„ ê³ ê°œ ìˆ™ì„"],
        "ìš´ë™_ì¶”ì²œ": {
            "ì˜ˆë°© (ìì„¸êµì •)": [
                {"name": "ëª© ìŠ¤íŠ¸ë ˆì¹­", "purpose": "ëª© ê·¼ìœ¡ ì´ì™„ ë° ìì„¸ êµì •", "method": "ê³ ê°œë¥¼ ì²œì²œíˆ ì¢Œìš°ë¡œ ëŒë¦¬ê³ , ì•ë’¤ë¡œ ìˆ™ì´ê¸°", "reps": "ê° ë°©í–¥ 10ì´ˆì”© 3íšŒ", "caution": "ê¸‰ê²©í•œ ì›€ì§ì„ ê¸ˆì§€"},
                {"name": "ì–´ê¹¨ ìœ¼ì“±í•˜ê¸°", "purpose": "ì–´ê¹¨ ê¸´ì¥ ì™„í™”", "method": "ì–´ê¹¨ë¥¼ ê·€ ìª½ìœ¼ë¡œ ì˜¬ë ¸ë‹¤ê°€ ì²œì²œíˆ ë‚´ë¦¬ê¸°", "reps": "10íšŒ 3ì„¸íŠ¸", "caution": "ì²œì²œíˆ ë¶€ë“œëŸ½ê²Œ ì‹¤ì‹œ"}
            ],
            "ìš´ë™ (ê·¼ë ¥ ë° ì²´ë ¥ ì¦ì§„)": [
                {"name": "ëª© ê·¼ë ¥ ê°•í™”", "purpose": "ëª© ì£¼ë³€ ê·¼ìœ¡ ê°•í™”", "method": "ì†ìœ¼ë¡œ ì´ë§ˆë¥¼ ëˆ„ë¥´ë©° ëª©ìœ¼ë¡œ ì €í•­í•˜ê¸°", "reps": "10ì´ˆì”© 5íšŒ", "caution": "ê³¼ë„í•œ í˜ ì‚¬ìš© ê¸ˆì§€"}
            ],
            "ì¬í™œ (í†µì¦ê°ì†Œ)": [
                {"name": "ì˜¨ì°œì§ˆ í›„ ìŠ¤íŠ¸ë ˆì¹­", "purpose": "í†µì¦ ì™„í™” ë° í˜ˆì•¡ìˆœí™˜ ê°œì„ ", "method": "ë”°ëœ»í•œ ìˆ˜ê±´ìœ¼ë¡œ ëª©ì„ ì°œì§ˆ í›„ ê°€ë²¼ìš´ ìŠ¤íŠ¸ë ˆì¹­", "reps": "15ë¶„ ì°œì§ˆ í›„ ìŠ¤íŠ¸ë ˆì¹­", "caution": "í†µì¦ì´ ì‹¬í•  ë•ŒëŠ” ì¤‘ë‹¨"}
            ]
        },
        "ìœ íŠœë¸Œ_ì˜ìƒ_ë§í¬": [
            {"title": "ê±°ë¶ëª© ìŠ¤íŠ¸ë ˆì¹­ 5ë¶„", "url": "https://www.youtube.com/watch?v=F0B6b9j8yJ8"},
            {"title": "ì¼ìëª© ìŠ¤íŠ¸ë ˆì¹­", "url": "https://www.youtube.com/watch?v=1F_454p-jR4"}
        ]
    },
    "ë¼ìš´ë“œìˆ„ë”": {
        "ì¦ìƒ": ["êµ½ì€ ë“±", "ê°€ìŠ´ í†µì¦", "í˜¸í¡ ê³¤ë€"],
        "ì›ì¸": ["ì¥ì‹œê°„ ì»´í“¨í„° ì‚¬ìš©", "ì˜ëª»ëœ ìì„¸"],
        "ìš´ë™_ì¶”ì²œ": {
            "ì˜ˆë°© (ìì„¸êµì •)": [
                {"name": "ê°€ìŠ´ ìŠ¤íŠ¸ë ˆì¹­", "purpose": "ê°€ìŠ´ ê·¼ìœ¡ ì´ì™„ìœ¼ë¡œ ì–´ê¹¨ êµì •", "method": "ë²½ì— ì†ì„ ëŒ€ê³  ëª¸ì„ ì•ìœ¼ë¡œ ê¸°ìš¸ì´ê¸°", "reps": "30ì´ˆì”© 3íšŒ", "caution": "ë¬´ë¦¬í•˜ì§€ ì•ŠëŠ” ë²”ìœ„ì—ì„œ"},
                {"name": "ì–´ê¹¨ë‚ ê°œ ëª¨ìœ¼ê¸°", "purpose": "ë“± ê·¼ìœ¡ ê°•í™”", "method": "ì–‘ìª½ ì–´ê¹¨ë‚ ê°œë¥¼ ë“± ì¤‘ì•™ìœ¼ë¡œ ëª¨ìœ¼ê¸°", "reps": "10ì´ˆì”© 10íšŒ", "caution": "ì–´ê¹¨ë¥¼ ì˜¬ë¦¬ì§€ ë§ê³  ì‹¤ì‹œ"}
            ],
            "ìš´ë™ (ê·¼ë ¥ ë° ì²´ë ¥ ì¦ì§„)": [
                {"name": "ë“± ê·¼ë ¥ ê°•í™”", "purpose": "ë“± ê·¼ìœ¡ ê°•í™”ë¡œ ìì„¸ ê°œì„ ", "method": "ì–‘íŒ”ì„ ë’¤ë¡œ ë‹¹ê¸°ë©° ì–´ê¹¨ë‚ ê°œ ëª¨ìœ¼ê¸°", "reps": "15íšŒ 3ì„¸íŠ¸", "caution": "ì²œì²œíˆ ì •í™•í•œ ìì„¸ë¡œ"}
            ],
            "ì¬í™œ (í†µì¦ê°ì†Œ)": [
                {"name": "ë¶€ë“œëŸ¬ìš´ ì–´ê¹¨ íšŒì „", "purpose": "ì–´ê¹¨ ê´€ì ˆ ê°€ë™ì„± ê°œì„ ", "method": "ì–´ê¹¨ë¥¼ ì²œì²œíˆ ì•ë’¤ë¡œ íšŒì „ì‹œí‚¤ê¸°", "reps": "ê° ë°©í–¥ 10íšŒì”©", "caution": "í†µì¦ ë²”ìœ„ ë‚´ì—ì„œë§Œ"}
            ]
        },
        "ìœ íŠœë¸Œ_ì˜ìƒ_ë§í¬": [
            {"title": "ë¼ìš´ë“œìˆ„ë” êµì • ìš´ë™", "url": "https://www.youtube.com/watch?v=4dJ4K1z7n5o"}
        ]
    },
    "í—ˆë¦¬ë””ìŠ¤í¬": {
        "ì¦ìƒ": ["í—ˆë¦¬ í†µì¦", "ë‹¤ë¦¬ ì €ë¦¼", "ê°ê° ì´ìƒ"],
        "ì›ì¸": ["ì¥ì‹œê°„ ì•‰ì•„ìˆê¸°", "ì˜ëª»ëœ ìì„¸", "ë¬´ê±°ìš´ ë¬¼ê±´ ë“¤ê¸°"],
        "ìš´ë™_ì¶”ì²œ": {
            "ì˜ˆë°© (ìì„¸êµì •)": [
                {"name": "ê³ ì–‘ì´-ì†Œ ìì„¸", "purpose": "í—ˆë¦¬ ê·¼ìœ¡ ì´ì™„", "method": "ë¬´ë¦ì„ ê¿‡ê³  ì†ë°”ë‹¥ì„ ë°”ë‹¥ì— ëŒ€ê³  í—ˆë¦¬ë¥¼ êµ½í˜”ë‹¤ íˆë‹¤ í•©ë‹ˆë‹¤.", "reps": "10íšŒì”© 3ì„¸íŠ¸", "caution": "ì²œì²œíˆ ë¶€ë“œëŸ½ê²Œ"},
                {"name": "ëˆ„ì›Œì„œ ë‹¤ë¦¬ ì˜¬ë¦¬ê¸°", "purpose": "í—ˆë¦¬ ê³¡ì„  ì •ìƒí™”", "method": "ë°”ë¡œ ëˆ„ì›Œ í•œìª½ ë‹¤ë¦¬ë¥¼ ì²œì²œíˆ ë“¤ì–´ì˜¬ë¦½ë‹ˆë‹¤.", "reps": "ê° ë‹¤ë¦¬ 10íšŒ", "caution": "í†µì¦ì´ ì—†ëŠ” ë²”ìœ„ì—ì„œ"}
            ],
            "ìš´ë™ (ê·¼ë ¥ ë° ì²´ë ¥ ì¦ì§„)": [
                {"name": "ì½”ì–´ ê°•í™”", "purpose": "í—ˆë¦¬ ì§€ì§€ ê·¼ìœ¡ ê°•í™”", "method": "ë°°ì— í˜ì„ ì£¼ê³  10ì´ˆê°„ ìœ ì§€", "reps": "10ì´ˆì”© 10íšŒ", "caution": "í˜¸í¡ì„ ë©ˆì¶”ì§€ ë§ ê²ƒ"}
            ],
            "ì¬í™œ (í†µì¦ê°ì†Œ)": [
                {"name": "ë¬´ë¦ ê°€ìŠ´ìœ¼ë¡œ ë‹¹ê¸°ê¸°", "purpose": "í—ˆë¦¬ ê·¼ìœ¡ ì´ì™„", "method": "ì•‰ì•„ì„œ í•œìª½ ë¬´ë¦ì„ ê°€ìŠ´ìœ¼ë¡œ ë‹¹ê¸°ê¸°", "reps": "ê° ë‹¤ë¦¬ 30ì´ˆì”©", "caution": "í†µì¦ì´ ìˆìœ¼ë©´ ì¤‘ë‹¨"}
            ]
        },
        "ìœ íŠœë¸Œ_ì˜ìƒ_ë§í¬": [
            {"title": "í—ˆë¦¬ë””ìŠ¤í¬ ì˜ˆë°© ìŠ¤íŠ¸ë ˆì¹­", "url": "https://www.youtube.com/watch?v=eYk2S9f2gI4"}
        ]
    },
    "ì†ëª©í„°ë„ì¦í›„êµ°": {
        "ì¦ìƒ": ["ì†ëª© í†µì¦", "ì†ê°€ë½ ì €ë¦¼", "ì† ê·¼ë ¥ ì•½í™”", "ë°¤ì— ì‹¬í•´ì§€ëŠ” ì†ëª© í†µì¦"],
        "ì›ì¸": ["ë°˜ë³µì ì¸ ì†ëª© ì‚¬ìš©", "ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ì†ëª© ê°ë„", "ì¥ì‹œê°„ ì»´í“¨í„° ì‚¬ìš©"],
        "ìš´ë™_ì¶”ì²œ": {
            "ì˜ˆë°© (ìì„¸êµì •)": [
                {"name": "ì†ëª© ìŠ¤íŠ¸ë ˆì¹­", "purpose": "ì†ëª© ê·¼ìœ¡ ì´ì™„", "method": "ì†ëª©ì„ ìœ„ì•„ë˜ë¡œ êµ¬ë¶€ë¦¬ê¸° (ì–‘ì†)", "reps": "10íšŒì”© 3ì„¸íŠ¸", "caution": "í†µì¦ ì‹œ ì¤‘ë‹¨"},
                {"name": "ì†ê°€ë½ í´ê¸°", "purpose": "ì†ê°€ë½ ê·¼ìœ¡ ì´ì™„", "method": "ì†ê°€ë½ì„ ì­‰ í´ê³  5ì´ˆê°„ ìœ ì§€", "reps": "10íšŒ", "caution": "ë¶€ë“œëŸ½ê²Œ ì‹¤ì‹œ"},
                {"name": "ì†ëª© ì¸¡ë©´ ìŠ¤íŠ¸ë ˆì¹­", "purpose": "ì†ëª© ì¸¡ë©´ ê·¼ìœ¡ ì´ì™„", "method": "ì†ëª©ì„ ì¢Œìš°ë¡œ ì –íˆê¸°", "reps": "ê° ë°©í–¥ 10ì´ˆì”© 3íšŒ", "caution": "ì„œì„œíˆ ì§„í–‰"}
            ],
            "ìš´ë™ (ê·¼ë ¥ ë° ì²´ë ¥ ì¦ì§„)": [
                {"name": "ì†ëª© ê·¼ë ¥ ê°•í™”", "purpose": "ì†ëª© ì£¼ë³€ ê·¼ìœ¡ ê°•í™”", "method": "ê°€ë²¼ìš´ ë¬´ê²Œë¡œ ì†ëª© êµ½íˆê¸° ìš´ë™", "reps": "15íšŒ 2ì„¸íŠ¸", "caution": "ë¬´ë¦¬í•˜ì§€ ë§ ê²ƒ"},
                {"name": "ì†ê°€ë½ ìš´ë™", "purpose": "ì†ê°€ë½ ê·¼ë ¥ ê°•í™”", "method": "ì£¼ë¨¹ ì¥ì—ˆë‹¤ í´ê¸° ë°˜ë³µ", "reps": "20íšŒ 2ì„¸íŠ¸", "caution": "ì²œì²œíˆ ì‹¤ì‹œ"}
            ],
            "ì¬í™œ (í†µì¦ê°ì†Œ)": [
                {"name": "ì‹ ê²½ í™œì£¼ ìš´ë™", "purpose": "ì‹ ê²½ ì••ë°• ì™„í™”", "method": "ì†ëª©ê³¼ ì†ê°€ë½ì„ ì²œì²œíˆ í´ê³  êµ¬ë¶€ë¦¬ê¸°", "reps": "10íšŒì”© í•˜ë£¨ 3ë²ˆ", "caution": "ì €ë¦¼ì´ ì‹¬í•´ì§€ë©´ ì¤‘ë‹¨"},
                {"name": "ì†ëª© ë§ˆì‚¬ì§€", "purpose": "í˜ˆì•¡ìˆœí™˜ ê°œì„ ", "method": "ì†ëª© ë¶€ìœ„ë¥¼ ë¶€ë“œëŸ½ê²Œ ë§ˆì‚¬ì§€", "reps": "2-3ë¶„", "caution": "ê°•í•˜ê²Œ ëˆ„ë¥´ì§€ ë§ ê²ƒ"}
            ]
        },
        "ìœ íŠœë¸Œ_ì˜ìƒ_ë§í¬": [
            {"title": "ì†ëª©í„°ë„ì¦í›„êµ° ìŠ¤íŠ¸ë ˆì¹­", "url": "https://www.youtube.com/watch?v=EiRC80FJbHU"},
            {"title": "ì†ëª© í†µì¦ ìŠ¤íŠ¸ë ˆì¹­", "url": "https://www.youtube.com/watch?v=9D_r_z0i9pI"},
            {"title": "ì†ëª©í„°ë„ ì¦í›„êµ° ì˜ˆë°©", "url": "https://www.youtube.com/watch?v=G96q6sL3FhY"}
        ]
    }
}

def normalize_condition_name(condition):
    """
    ì¦ìƒëª…ì„ ì •ê·œí™”í•©ë‹ˆë‹¤. ì†ëª©í„°ë„ì¦í›„êµ°ì˜ ì¢Œ/ìš° êµ¬ë¶„ì„ í†µì¼í•©ë‹ˆë‹¤.
    """
    if "ì†ëª©í„°ë„ì¦í›„êµ°" in condition:
        return "ì†ëª©í„°ë„ì¦í›„êµ°"
    return condition

def get_exercises_for_condition(condition, purpose="ì˜ˆë°© (ìì„¸êµì •)"):
    """
    íŠ¹ì • ì¦ìƒì— ëŒ€í•œ ìš´ë™ ì¶”ì²œ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì¦ìƒëª… ì •ê·œí™”
    normalized_condition = normalize_condition_name(condition)
    return VDT_SYMPTOMS.get(normalized_condition, {}).get("ìš´ë™_ì¶”ì²œ", {}).get(purpose, [])

def get_exercise_videos(condition):
    """
    íŠ¹ì • ì¦ìƒì— ëŒ€í•œ YouTube ì˜ìƒ ëª©ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì¦ìƒëª… ì •ê·œí™”
    normalized_condition = normalize_condition_name(condition)
    videos = VDT_SYMPTOMS.get(normalized_condition, {}).get("ìœ íŠœë¸Œ_ì˜ìƒ_ë§í¬", [])
    if not videos:
        return []

    day_of_year = date.today().timetuple().tm_yday
    random.seed(day_of_year)
    
    return [random.choice(videos)]

def _fetch_videos_from_sheet(condition: str, purpose: str, limit: int):
    """Google Sheetsì˜ vdt_videos ì‹œíŠ¸ì—ì„œ ì¡°ê±´/ëª©ì  ê¸°ë°˜ ì˜ìƒ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        if not GOOGLE_SHEETS_ENABLED:
            return []
        
        client = init_google_sheets()
        if not client:
            return []
            
        spreadsheet = client.open_by_key(SPREADSHEET_ID)
        
        # ì‹œíŠ¸ ì—´ê¸°
        try:
            videos_ws = spreadsheet.worksheet("vdt_videos")
        except Exception:
            return []
        
        records = videos_ws.get_all_records()
        if not records:
            return []
        
        df = pd.DataFrame(records)
        
        # ì¡°ê±´ê³¼ ëª©ì ì— ë§ëŠ” ì˜ìƒ í•„í„°ë§
        filtered_df = df[
            (df['condition'].str.contains(condition, case=False, na=False)) &
            (df['purpose'].str.contains(purpose, case=False, na=False))
        ]
        
        if filtered_df.empty:
            return []
        
        # ì œí•œëœ ìˆ˜ë§Œí¼ ë°˜í™˜
        videos = []
        for _, row in filtered_df.head(limit).iterrows():
            videos.append({
                'title': row.get('title', ''),
                'url': row.get('url', ''),
                'channel_name': row.get('channel_name', ''),
                'duration_seconds': row.get('duration_seconds', 0)
            })
        
        return videos
        
    except Exception as e:
        return []

def get_videos_for_condition_enhanced(condition: str, purpose: str = "ì˜ˆë°©", limit: int = 3):
    """í–¥ìƒëœ ì˜ìƒ ì¶”ì²œ ì‹œìŠ¤í…œ: ë°ì´í„°ë² ì´ìŠ¤ > Google Sheets > í•˜ë“œì½”ë”© ìˆœì„œë¡œ ì‹œë„"""
    # ì¡°ê±´ëª… ì •ê·œí™”
    normalized_condition = normalize_condition_name(condition)
    videos = []
    
    # 1. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
    if YOUTUBE_SEARCH_AVAILABLE:
        try:
            db_videos = get_videos_for_condition(normalized_condition)
            if db_videos:
                videos.extend(db_videos[:limit])
        except Exception:
            pass
    
    # 2. Google Sheetsì—ì„œ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
    if not videos and GOOGLE_SHEETS_ENABLED:
        try:
            sheet_videos = _fetch_videos_from_sheet(normalized_condition, purpose, limit)
            if sheet_videos:
                videos.extend(sheet_videos)
        except Exception:
            pass
    
    # 3. í•˜ë“œì½”ë”©ëœ ì˜ìƒìœ¼ë¡œ fallback
    if not videos:
        try:
            hardcoded_videos = get_exercise_videos(normalized_condition)
            if hardcoded_videos:
                videos.extend(hardcoded_videos)
        except Exception:
            pass
    
    return videos[:limit]

def show_integrated_dashboard(user_email=None):
    """í†µí•© ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥ - ì´ë©”ì¼ ê¸°ì¤€ ì‚¬ìš©ì ê´€ë¦¬"""
    st.header("ğŸ’» í†µí•© ê±´ê°• ëŒ€ì‹œë³´ë“œ")
    
    # ê°œì¸ì •ë³´ ì…ë ¥ ì™„ë£Œ ì—¬ë¶€ í™•ì¸ (ì´ë©”ì¼ ê¸°ì¤€)
    if not user_email:
        st.warning("â— ë¨¼ì € 'ê°œì¸ì •ë³´ ì…ë ¥' íƒ­ì—ì„œ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.info("ğŸ’¡ ê°œì¸ì •ë³´ê°€ ì…ë ¥ëœ í›„ì— ìš´ë™ ê´€ë¦¬ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ“ ê°œì¸ì •ë³´ ì…ë ¥í•˜ëŸ¬ ê°€ê¸°", type="primary"):
                st.session_state.menu_selection = "ì¦ìƒ ì„ íƒ"
                st.rerun()
        
        return
    
    # ë¡œê·¸ì¸ëœ ì‚¬ìš©ì í‘œì‹œ
    st.success(f"ğŸ‘¤ í™˜ì˜í•©ë‹ˆë‹¤! {user_email}ë‹˜ì˜ ìš´ë™ ê´€ë¦¬ í˜ì´ì§€ì…ë‹ˆë‹¤.")
    st.markdown("ì˜¤ëŠ˜ì˜ ìš´ë™ ë£¨í‹´ì„ ì™„ë£Œí•˜ê³ , í†µì¦ì„ ê¸°ë¡í•˜ë©° ê±´ê°•ì„ ê´€ë¦¬í•˜ì„¸ìš”.")
    st.markdown("---")
    
    if GOOGLE_SHEETS_ENABLED:
        st.info("ğŸ“Š Google Sheetsì™€ ì—°ê²°ë˜ì–´ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê³  ë¶ˆëŸ¬ì˜µë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ Google Sheetsê°€ ì—°ê²°ë˜ì§€ ì•Šì•„ ë¡œì»¬ ë°ì´í„°ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # YouTube ì—°ê²° ìƒíƒœ í‘œì‹œ
    if YOUTUBE_SEARCH_AVAILABLE:
        st.success("ğŸ¥ YouTube ì˜ìƒ ì¶”ì²œ ì‹œìŠ¤í…œì´ í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        st.warning("âš ï¸ YouTube ì˜ìƒ ì¶”ì²œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•˜ë ¤ë©´ ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•˜ì„¸ìš”.")
    
    st.markdown("---")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'exercise_log' not in st.session_state:
        st.session_state.exercise_log = {}
    if 'pain_data' not in st.session_state:
        st.session_state.pain_data = {}
    if 'checkbox_states' not in st.session_state:
        st.session_state.checkbox_states = {}
    
    today = str(date.today())
    
    # ì¦ìƒ ì„ íƒ - ì´ë¯¸ ì„ íƒëœ ì¦ìƒ ì‚¬ìš©
    st.subheader("ğŸ” í˜„ì¬ ê´€ë¦¬ ì¤‘ì¸ ì¦ìƒ")
    
    # ì„¸ì…˜ì—ì„œ ì´ë¯¸ ì„ íƒëœ ì¦ìƒ ê°€ì ¸ì˜¤ê¸°
    if hasattr(st.session_state, 'selected_conditions') and st.session_state.selected_conditions:
        selected_conditions = st.session_state.selected_conditions
        st.success(f"âœ… ì„ íƒëœ ì¦ìƒ: {', '.join(selected_conditions)}")
        
        # ì¶”ê°€ ì¦ìƒì´ ìˆëŠ”ì§€ í™•ì¸
        symptom_options = list(VDT_SYMPTOMS.keys())
        remaining_symptoms = [sym for sym in symptom_options if sym not in selected_conditions]
        
        if remaining_symptoms:
            additional_conditions = st.multiselect(
                "ì¶”ê°€ë¡œ ê´€ë¦¬í•˜ê³  ì‹¶ì€ ì¦ìƒì´ ìˆë‚˜ìš”?",
                remaining_symptoms
            )
            if additional_conditions:
                selected_conditions.extend(additional_conditions)
                st.info(f"ğŸ“ ì¶”ê°€ëœ ì¦ìƒ: {', '.join(additional_conditions)}")
    else:
        st.warning("âš ï¸ ë¨¼ì € 'ì¦ìƒ ì„ íƒ' ë©”ë‰´ì—ì„œ ì¦ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
        symptom_options = list(VDT_SYMPTOMS.keys())
        selected_conditions = st.multiselect(
            "ì¦ìƒì„ ì„ íƒí•´ì£¼ì„¸ìš”:",
            symptom_options
        )
    
    st.markdown("---")
    
    # ì˜¤ëŠ˜ì˜ ë£¨í‹´
    st.subheader("ğŸƒâ€â™‚ï¸ ì˜¤ëŠ˜ì˜ ë£¨í‹´")
    if not selected_conditions:
        st.info("ë¨¼ì € ìœ„ì—ì„œ ì¦ìƒì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        for condition in selected_conditions:
            st.markdown(f"**ğŸ”¹ {condition}**")
            
            # ì¡°ê±´ëª… ì •ê·œí™”
            normalized_condition = normalize_condition_name(condition)
            
            # ì¦ìƒê³¼ ì›ì¸ í‘œì‹œ
            if normalized_condition in VDT_SYMPTOMS and "ì¦ìƒ" in VDT_SYMPTOMS[normalized_condition]:
                st.markdown("**ğŸ“‹ ì£¼ìš” ì¦ìƒ:**")
                symptoms = VDT_SYMPTOMS[normalized_condition]["ì¦ìƒ"]
                for symptom in symptoms:
                    st.markdown(f"â€¢ {symptom}")
            
            if "ì›ì¸" in VDT_SYMPTOMS[normalized_condition]:
                st.markdown("**ğŸ” ì£¼ìš” ì›ì¸:**")
                causes = VDT_SYMPTOMS[normalized_condition]["ì›ì¸"]
                for cause in causes:
                    st.markdown(f"â€¢ {cause}")
            
            st.markdown("---")
            
            # ìš´ë™ ì¶”ì²œ
            if "ìš´ë™_ì¶”ì²œ" in VDT_SYMPTOMS[normalized_condition]:
                exercises = VDT_SYMPTOMS[normalized_condition]["ìš´ë™_ì¶”ì²œ"]
                for purpose, exercise_list in exercises.items():
                    st.markdown(f"**âœ¨ {purpose} ìš´ë™**")
                    for exercise in exercise_list:
                        # ê³ ìœ í•œ ì²´í¬ë°•ìŠ¤ í‚¤ ìƒì„±
                        unique_key = f"completed_exercise_{today}_{condition}_{exercise['name']}"
                        
                        # ì²´í¬ë°•ìŠ¤ ìƒíƒœë¥¼ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•˜ê³  ë¡œë“œ
                        if unique_key not in st.session_state.checkbox_states:
                            st.session_state.checkbox_states[unique_key] = False
                            
                        # ì²´í¬ë°•ìŠ¤ í‘œì‹œ ë° ìƒíƒœ ë³€ê²½ ì‹œ ì„¸ì…˜ ì—…ë°ì´íŠ¸
                        st.session_state.checkbox_states[unique_key] = st.checkbox(
                            f"**{exercise['name']}**",
                            value=st.session_state.checkbox_states[unique_key],
                            key=unique_key
                        )

                        # ìš´ë™ ìƒì„¸ ì •ë³´ í‘œì‹œ
                        st.markdown(
                            f"""
                            - **ëª©ì :** {exercise['purpose']}
                            - **ë°©ë²•:** {exercise['method']}
                            - **ë°˜ë³µ:** {exercise['reps']}
                            """
                        )
                        if "caution" in exercise:
                            st.markdown(f"âš ï¸ **ì£¼ì˜ì‚¬í•­:** {exercise['caution']}")
            
            st.markdown("---")
            
            # ìœ íŠœë¸Œ ì˜ìƒ í‘œì‹œ
            st.markdown("**ğŸ“º ì¶”ì²œ ì˜ìƒ**")
            try:
                videos = get_videos_for_condition_enhanced(normalized_condition, "ì˜ˆë°©", 2)
                if videos:
                    for i, video in enumerate(videos):
                        if 'url' in video and video['url']:
                            # í•˜ì´í¼ë§í¬ë¡œë§Œ í‘œì‹œ (ì¸ë„¤ì¼ ì—†ìŒ)
                            video_title = video.get('title', 'ì¶”ì²œ ì˜ìƒ')
                            video_url = video['url']
                            st.markdown(f"**[{video_title}]({video_url})**")
                            
                            # ìœ íŠœë¸Œ ì˜ìƒ ì™„ë£Œ ì²´í¬ë°•ìŠ¤ ì¶”ê°€
                            video_key = f"completed_video_{today}_{condition}_{video.get('title', 'ì¶”ì²œ ì˜ìƒ')}"
                            if video_key not in st.session_state.checkbox_states:
                                st.session_state.checkbox_states[video_key] = False
                            # ì²´í¬ë°•ìŠ¤ ìƒíƒœì— ë”°ë¼ ë¼ë²¨ ë™ì  ë³€ê²½
                            is_watched = st.session_state.checkbox_states[video_key]
                            checkbox_label = f"**{video.get('title', 'ì¶”ì²œ ì˜ìƒ')}** {'âœ… ì‹œì²­ ì™„ë£Œ' if is_watched else 'â–¶ï¸ ì‹œì²­í•˜ê¸°'}"
                            
                            st.session_state.checkbox_states[video_key] = st.checkbox(
                                checkbox_label,
                                value=st.session_state.checkbox_states[video_key],
                                key=video_key
                            )
                else:
                    st.info("í•´ë‹¹ ì¦ìƒì— ëŒ€í•œ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.warning(f"ì˜ìƒ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                # í•˜ë“œì½”ë”©ëœ ì˜ìƒìœ¼ë¡œ fallback
                try:
                    fallback_videos = get_exercise_videos(condition)
                    if fallback_videos:
                        for video in fallback_videos:
                            if 'url' in video and video['url']:
                                # í•˜ì´í¼ë§í¬ë¡œë§Œ í‘œì‹œ (ì¸ë„¤ì¼ ì—†ìŒ)
                                video_title = video.get('title', 'ì¶”ì²œ ì˜ìƒ')
                                video_url = video['url']
                                st.markdown(f"**[{video_title}]({video_url})**")
                                
                                # í•˜ë“œì½”ë”©ëœ ì˜ìƒë„ ì²´í¬ë°•ìŠ¤ ì¶”ê°€
                                video_key = f"completed_video_{today}_{condition}_{video.get('title', 'ì¶”ì²œ ì˜ìƒ')}"
                                if video_key not in st.session_state.checkbox_states:
                                    st.session_state.checkbox_states[video_key] = False
                                # í•˜ë“œì½”ë”©ëœ ì˜ìƒë„ ë™ì  ë¼ë²¨ ì ìš©
                                is_watched = st.session_state.checkbox_states[video_key]
                                checkbox_label = f"**{video.get('title', 'ì¶”ì²œ ì˜ìƒ')}** {'âœ… ì‹œì²­ ì™„ë£Œ' if is_watched else 'â–¶ï¸ ì‹œì²­í•˜ê¸°'}"
                                
                                st.session_state.checkbox_states[video_key] = st.checkbox(
                                    checkbox_label,
                                    value=st.session_state.checkbox_states[video_key],
                                    key=video_key
                                )
                except Exception:
                    st.info("ì˜ìƒì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            st.markdown("---")
    
    # ìš´ë™ ì™„ë£Œ ê¸°ë¡
    st.subheader("ğŸ’ª ìš´ë™ ì™„ë£Œ ê¸°ë¡")
    
    if st.button("ìš´ë™ ì™„ë£Œ ê¸°ë¡"):
        completed_exercises = []
        completed_videos = []
        
        # ëª¨ë“  ì²´í¬ë°•ìŠ¤ë¥¼ ìˆœíšŒí•˜ë©° ì™„ë£Œëœ ìš´ë™ì„ ê¸°ë¡
        for key, value in st.session_state.checkbox_states.items():
            if value and key.startswith(f"completed_exercise_{today}"):
                completed_exercises.append(key)
            elif value and key.startswith(f"completed_video_{today}"):
                completed_videos.append(key)
        
        total_completed = len(completed_exercises) + len(completed_videos)
        
        if total_completed > 0:
            st.session_state.exercise_log[today] = total_completed
            
            # í†µí•© ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            from customer_database import save_exercise_record
            db_saved = save_exercise_record(user_email, 'exercise_log', total_completed, today)
            
            # ë°±ì—…: Google Sheetsì™€ ë¡œì»¬ ì €ì¥
            google_saved = save_to_google_sheets(total_completed, 'exercise_log', user_email)
            local_saved = save_to_local_json(total_completed, 'exercise_log', user_email)
            
            # ì €ì¥ ìƒíƒœ í‘œì‹œ
            if db_saved:
                st.success("âœ… ìš´ë™ ê¸°ë¡ì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            elif google_saved or local_saved:
                st.success("âœ… ìš´ë™ ê¸°ë¡ì´ ë°±ì—… ì €ì¥ì†Œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            else:
                st.warning("âš ï¸ ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë¡œì»¬ ì €ì¥ì„ ì‹œë„í•©ë‹ˆë‹¤.")
                # ë¡œì»¬ ë°±ì—… ì €ì¥
                try:
                    backup_data = {
                        'user_id': user_email,
                        'date': today,
                        'data_type': 'exercise_log',
                        'value': total_completed,
                        'timestamp': datetime.now().isoformat()
                    }
                    
                    backup_file = "local_exercise_backup.json"
                    existing_data = []
                    if os.path.exists(backup_file):
                        with open(backup_file, 'r', encoding='utf-8') as f:
                            content = f.read().strip()
                            if content:
                                existing_data = json.loads(content)
                    
                    existing_data.append(backup_data)
                    
                    with open(backup_file, 'w', encoding='utf-8') as f:
                        json.dump(existing_data, f, ensure_ascii=False, indent=2)
                    
                    st.success("ğŸ’¾ ë°ì´í„°ê°€ ë¡œì»¬ ë°±ì—… íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"ë¡œì»¬ ë°±ì—… ì €ì¥ë„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
            
            st.success(f"âœ… ìš´ë™ ì™„ë£Œ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.success(f"ğŸ“Š ì™„ë£Œ í•­ëª©: ìš´ë™ {len(completed_exercises)}ê°œ + ì˜ìƒ ì‹œì²­ {len(completed_videos)}ê°œ = ì´ {total_completed}ê°œ")
            
            # ì™„ë£Œëœ í•­ëª©ë“¤ í‘œì‹œ
            if completed_exercises:
                st.info("âœ… ì™„ë£Œëœ ìš´ë™:")
                for exercise_key in completed_exercises:
                    exercise_name = exercise_key.split('_')[-1]
                    st.write(f"â€¢ {exercise_name}")
            
            if completed_videos:
                st.info("ğŸ“º ì‹œì²­ ì™„ë£Œí•œ ì˜ìƒ:")
                for video_key in completed_videos:
                    video_name = video_key.split('_')[-1]
                    st.write(f"â€¢ {video_name}")
        else:
            st.warning("âš ï¸ ì™„ë£Œí•œ ìš´ë™ì´ë‚˜ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        
        st.rerun()
    
    # í†µì¦ ê¸°ë¡
    st.subheader("ğŸ¥ ë‚˜ì˜ í†µì¦ ê¸°ë¡í•˜ê¸°")
    current_pain_level = st.slider(
        "ì˜¤ëŠ˜ì˜ í†µì¦ ì ìˆ˜ (0: ì—†ìŒ, 15: ì‹¬í•¨)",
        0, 15, key="pain_slider"
    )
    
    # í†µì¦ ë‹¨ê³„ë³„ ì´ëª¨ì§€ í‘œì‹œ
    pain_emoji_map = {
        0: "ğŸ˜Š ì—†ìŒ",
        1: "ğŸ™‚ ë¯¸ë¯¸í•¨", 2: "ğŸ™‚ ë¯¸ë¯¸í•¨", 3: "ğŸ™‚ ë¯¸ë¯¸í•¨",
        4: "ğŸ˜ ì•½í•¨", 5: "ğŸ˜ ì•½í•¨", 6: "ğŸ˜ ì•½í•¨",  
        7: "ğŸ˜Ÿ ë³´í†µ", 8: "ğŸ˜Ÿ ë³´í†µ", 9: "ğŸ˜Ÿ ë³´í†µ",
        10: "ğŸ˜° ì‹¬í•¨", 11: "ğŸ˜° ì‹¬í•¨", 12: "ğŸ˜° ì‹¬í•¨",
        13: "ğŸ˜± ë§¤ìš°ì‹¬í•¨", 14: "ğŸ˜± ë§¤ìš°ì‹¬í•¨", 15: "ğŸ˜± ê·¹ì‹¬í•¨"
    }
    
    if current_pain_level in pain_emoji_map:
        st.markdown(f"### {pain_emoji_map[current_pain_level]}")
        
        # í†µì¦ ì •ë„ë³„ ì„¤ëª…
        if current_pain_level == 0:
            st.info("ğŸ‘ í†µì¦ì´ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤.")
        elif 1 <= current_pain_level <= 3:
            st.info("ğŸ’š ë§¤ìš° ê²½ë¯¸í•œ í†µì¦ì…ë‹ˆë‹¤. ì¼ìƒìƒí™œì— ì§€ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        elif 4 <= current_pain_level <= 6:
            st.warning("ğŸ’› ì•½í•œ í†µì¦ì…ë‹ˆë‹¤. ê°€ë²¼ìš´ ìš´ë™ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        elif 7 <= current_pain_level <= 9:
            st.warning("ğŸ§¡ ë³´í†µ í†µì¦ì…ë‹ˆë‹¤. íœ´ì‹ê³¼ ìŠ¤íŠ¸ë ˆì¹­ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        elif 10 <= current_pain_level <= 12:
            st.error("â¤ï¸ ì‹¬í•œ í†µì¦ì…ë‹ˆë‹¤. ì „ë¬¸ì˜ ìƒë‹´ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        else:  # 13-15
            st.error("ğŸ’” ê·¹ì‹¬í•œ í†µì¦ì…ë‹ˆë‹¤. ì¦‰ì‹œ ì „ë¬¸ì˜ ì§„ë£Œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    if st.button("í†µì¦ ê¸°ë¡ ì €ì¥"):
        st.session_state.pain_data[today] = current_pain_level
        
        # í†µí•© ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        from customer_database import save_exercise_record
        db_saved = save_exercise_record(user_email, 'pain_data', current_pain_level, today)
        
        # ë°±ì—…: Google Sheetsì™€ ë¡œì»¬ ì €ì¥
        google_saved = save_to_google_sheets(current_pain_level, 'pain_data', user_email)
        local_saved = save_to_local_json(current_pain_level, 'pain_data', user_email)
        
        # ì €ì¥ ìƒíƒœ í‘œì‹œ
        if db_saved:
            st.success("âœ… í†µì¦ ê¸°ë¡ì´ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        elif google_saved or local_saved:
            st.success("âœ… í†µì¦ ê¸°ë¡ì´ ë°±ì—… ì €ì¥ì†Œì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!")
        else:
            st.warning("âš ï¸ í†µì¦ ë°ì´í„° ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        st.success(f"âœ… í†µì¦ ê¸°ë¡ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (í†µì¦ ì ìˆ˜: {current_pain_level}/15)")
        st.rerun()
    
    st.markdown("---")
    
    # í†µì¦Â·ìš´ë™ ë¦¬í¬íŠ¸
    st.subheader("ğŸ“ˆ í†µì¦Â·ìš´ë™ ë¦¬í¬íŠ¸")
    
    # ë°ì´í„° ë¡œë“œ (ì„¸ì…˜ ìƒíƒœ ìš°ì„ , Google Sheetsì—ì„œ ë¡œë“œ, ì‹¤íŒ¨ì‹œ ë¡œì»¬ JSON íŒŒì¼ì—ì„œ)
    exercise_df = pd.DataFrame()
    pain_df = pd.DataFrame()
    
    # 0. í†µí•© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ
    try:
        from customer_database import get_exercise_records
        
        # ìš´ë™ ê¸°ë¡ ë¡œë“œ
        exercise_records = get_exercise_records(user_email, 'exercise_log', days=30)
        if exercise_records:
            db_exercise_df = pd.DataFrame(exercise_records)
            db_exercise_df['date'] = pd.to_datetime(db_exercise_df['record_date'])
            db_exercise_df['completed_count'] = pd.to_numeric(db_exercise_df['value'], errors='coerce').fillna(0)
            db_exercise_df['user_id'] = user_email
            exercise_df = db_exercise_df[['user_id', 'date', 'completed_count']].copy()
        
        # í†µì¦ ê¸°ë¡ ë¡œë“œ
        pain_records = get_exercise_records(user_email, 'pain_data', days=30)
        if pain_records:
            db_pain_df = pd.DataFrame(pain_records)
            db_pain_df['date'] = pd.to_datetime(db_pain_df['record_date'])
            db_pain_df['pain_level'] = pd.to_numeric(db_pain_df['value'], errors='coerce').fillna(0)
            db_pain_df['user_id'] = user_email
            pain_df = db_pain_df[['user_id', 'date', 'pain_level']].copy()
        
        if not exercise_df.empty or not pain_df.empty:
            st.info("âœ… í†µí•© ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        st.info("ğŸ’¡ í†µí•© ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°ì„ ê±´ë„ˆë›°ê³  ë°±ì—… ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # 1. ì„¸ì…˜ ìƒíƒœì—ì„œ ì˜¤ëŠ˜ ë°ì´í„° ì¶”ê°€ (ì‹¤ì‹œê°„ ë°˜ì˜)
    today = str(date.today())
    if today in st.session_state.exercise_log:
        today_exercise = pd.DataFrame({
            'user_id': [user_email],
            'date': [pd.to_datetime(today)],
            'completed_count': [st.session_state.exercise_log[today]]
        })
        if not exercise_df.empty:
            # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì¶”ê°€
            exercise_df = exercise_df[exercise_df['date'].dt.date != date.today()]
            exercise_df = pd.concat([exercise_df, today_exercise])
        else:
            exercise_df = today_exercise
    
    if today in st.session_state.pain_data:
        today_pain = pd.DataFrame({
            'user_id': [user_email],
            'date': [pd.to_datetime(today)],
            'pain_level': [st.session_state.pain_data[today]]
        })
        if not pain_df.empty:
            # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì—…ë°ì´íŠ¸, ì—†ìœ¼ë©´ ì¶”ê°€
            pain_df = pain_df[pain_df['date'].dt.date != date.today()]
            pain_df = pd.concat([pain_df, today_pain])
        else:
            pain_df = today_pain
    
    # 2. Google Sheetsì—ì„œ ë°ì´í„° ë¡œë“œ ì‹œë„
    if GOOGLE_SHEETS_ENABLED:
        try:
            client = init_google_sheets()
            if client:
                spreadsheet = client.open_by_key(SPREADSHEET_ID)
                
                # exercise_log ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ
                try:
                    exercise_ws = spreadsheet.worksheet("exercise_log")
                    exercise_records = exercise_ws.get_all_records()
                    if exercise_records:
                        sheet_exercise_df = pd.DataFrame(exercise_records)
                        sheet_exercise_df['date'] = pd.to_datetime(sheet_exercise_df.iloc[:, 0])  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ timestamp
                        sheet_exercise_df['completed_count'] = pd.to_numeric(sheet_exercise_df.iloc[:, 2], errors='coerce').fillna(0)  # ì„¸ ë²ˆì§¸ ì»¬ëŸ¼ì´ value
                        sheet_exercise_df['user_id'] = sheet_exercise_df.iloc[:, 1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ user_id
                        
                        # ë‚ ì§œë³„ë¡œ ì¤‘ë³µ ì œê±° (ê°€ì¥ ìµœê·¼ ë°ì´í„°ë§Œ ìœ ì§€)
                        sheet_exercise_df = sheet_exercise_df.sort_values('date').drop_duplicates(subset=['date'], keep='last')
                        
                        # ì„¸ì…˜ ë°ì´í„°ì™€ ë³‘í•©
                        if not exercise_df.empty:
                            # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                            exercise_df = pd.concat([sheet_exercise_df[sheet_exercise_df['date'].dt.date != date.today()], exercise_df])
                        else:
                            exercise_df = sheet_exercise_df
                except Exception as e:
                    st.info("ğŸ’¡ Google Sheets ì—°ê²°ì„ ê±´ë„ˆë›°ê³  ë¡œì»¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                
                # pain_data ì‹œíŠ¸ì—ì„œ ë°ì´í„° ë¡œë“œ
                try:
                    pain_ws = spreadsheet.worksheet("pain_data")
                    pain_records = pain_ws.get_all_records()
                    if pain_records:
                        sheet_pain_df = pd.DataFrame(pain_records)
                        sheet_pain_df['date'] = pd.to_datetime(sheet_pain_df.iloc[:, 0])  # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì´ timestamp
                        sheet_pain_df['pain_level'] = pd.to_numeric(sheet_pain_df.iloc[:, 2], errors='coerce')  # ì„¸ ë²ˆì§¸ ì»¬ëŸ¼ì´ value
                        sheet_pain_df['user_id'] = sheet_pain_df.iloc[:, 1]  # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ì´ user_id
                        
                        # ë‚ ì§œë³„ë¡œ ì¤‘ë³µ ì œê±° (ê°€ì¥ ìµœê·¼ ë°ì´í„°ë§Œ ìœ ì§€)
                        sheet_pain_df = sheet_pain_df.sort_values('date').drop_duplicates(subset=['date'], keep='last')
                        
                        # ì„¸ì…˜ ë°ì´í„°ì™€ ë³‘í•©
                        if not pain_df.empty:
                            # ì˜¤ëŠ˜ ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë®ì–´ì“°ê¸°
                            pain_df = pd.concat([sheet_pain_df[sheet_pain_df['date'].dt.date != date.today()], pain_df])
                        else:
                            pain_df = sheet_pain_df
                except Exception as e:
                    st.info("ğŸ’¡ Google Sheets ì—°ê²°ì„ ê±´ë„ˆë›°ê³  ë¡œì»¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                    
        except Exception as e:
            st.info("ğŸ’¡ Google Sheets ì—°ê²°ì„ ê±´ë„ˆë›°ê³  ë¡œì»¬ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    
    # 3. Google Sheetsì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í•œ ê²½ìš° ë¡œì»¬ JSON íŒŒì¼ì—ì„œ ë¡œë“œ
    if exercise_df.empty and pain_df.empty:
        json_file = "local_exercise_data.json"
        if os.path.exists(json_file):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    file_content = f.read().strip()
                    if file_content:  # íŒŒì¼ì´ ë¹„ì–´ìˆì§€ ì•Šì€ì§€ í™•ì¸
                        data = json.loads(file_content)
                    else:
                        data = []
                
                if data:
                    df = pd.DataFrame(data)
                    
                    # ìš´ë™ ë¡œê·¸ ë°ì´í„°
                    exercise_data = df[df['data_type'] == 'exercise_log'].copy()
                    if not exercise_data.empty:
                        json_exercise_df = exercise_data[['user_id', 'date', 'value']].copy()
                        json_exercise_df['date'] = pd.to_datetime(json_exercise_df['date'])
                        json_exercise_df['completed_count'] = pd.to_numeric(json_exercise_df['value'], errors='coerce').fillna(0)
                        # ë‚ ì§œë³„ë¡œ ì¤‘ë³µ ì œê±° (ê°€ì¥ ìµœê·¼ ë°ì´í„°ë§Œ ìœ ì§€)
                        json_exercise_df = json_exercise_df.sort_values('date').drop_duplicates(subset=['date'], keep='last')
                        
                        # ì„¸ì…˜ ë°ì´í„°ì™€ ë³‘í•©
                        if not exercise_df.empty:
                            exercise_df = pd.concat([json_exercise_df[json_exercise_df['date'].dt.date != date.today()], exercise_df])
                        else:
                            exercise_df = json_exercise_df
                    
                    # í†µì¦ ë°ì´í„°
                    pain_data = df[df['data_type'] == 'pain_data'].copy()
                    if not pain_data.empty:
                        json_pain_df = pain_data[['user_id', 'date', 'value']].copy()
                        json_pain_df['date'] = pd.to_datetime(json_pain_df['date'])
                        json_pain_df['pain_level'] = pd.to_numeric(json_pain_df['value'], errors='coerce')
                        # ë‚ ì§œë³„ë¡œ ì¤‘ë³µ ì œê±° (ê°€ì¥ ìµœê·¼ ë°ì´í„°ë§Œ ìœ ì§€)
                        json_pain_df = json_pain_df.sort_values('date').drop_duplicates(subset=['date'], keep='last')
                        
                        # ì„¸ì…˜ ë°ì´í„°ì™€ ë³‘í•©
                        if not pain_df.empty:
                            pain_df = pd.concat([json_pain_df[json_pain_df['date'].dt.date != date.today()], pain_df])
                        else:
                            pain_df = json_pain_df
            except Exception as e:
                st.warning(f"ë¡œì»¬ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    # ë°ì´í„° ë¡œë“œ ìƒíƒœ í‘œì‹œ
    if not exercise_df.empty or not pain_df.empty:
        st.success("âœ… ë°ì´í„°ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤!")
    else:
        st.warning("âš ï¸ ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ìš´ë™ê³¼ í†µì¦ì„ ê¸°ë¡í•´ë³´ì„¸ìš”!")
    
    # ê·¸ë˜í”„ ìƒì„±
    if not exercise_df.empty or not pain_df.empty:
        try:
            # ì‚¬ìš©ì ë°ì´í„° í•„í„°ë§ (ì´ë©”ì¼ ê¸°ì¤€)
            if not exercise_df.empty:
                user_exercise_df = exercise_df[exercise_df['user_id'] == user_email].copy()
                if user_exercise_df.empty:
                    st.info("í•´ë‹¹ ì´ë©”ì¼ë¡œ ì €ì¥ëœ ìš´ë™ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                    user_exercise_df = pd.DataFrame()
            else:
                user_exercise_df = pd.DataFrame()

            if not pain_df.empty:
                user_pain_df = pain_df[pain_df['user_id'] == user_email].copy()
                if user_pain_df.empty:
                    st.info("í•´ë‹¹ ì´ë©”ì¼ë¡œ ì €ì¥ëœ í†µì¦ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
                    user_pain_df = pd.DataFrame()
            else:
                user_pain_df = pd.DataFrame()
            
            # ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì°¨íŠ¸ ìƒì„±
            if not user_exercise_df.empty or not user_pain_df.empty:
                # ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
                if not user_exercise_df.empty:
                    user_exercise_df = user_exercise_df.set_index('date')
                if not user_pain_df.empty:
                    user_pain_df = user_pain_df.set_index('date')
        
                # ë‘ ë°ì´í„°í”„ë ˆì„ì˜ ë‚ ì§œ ì¸ë±ìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ê²°í•©
                if not user_exercise_df.empty and not user_pain_df.empty:
                    combined_index = user_exercise_df.index.union(user_pain_df.index)
                elif not user_exercise_df.empty:
                    combined_index = user_exercise_df.index
                else:
                    combined_index = user_pain_df.index
                
                combined_df = pd.DataFrame(index=combined_index)
                
                # joinì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë³‘í•©
                if not user_exercise_df.empty:
                    combined_df = combined_df.join(user_exercise_df[['completed_count']])
                
                if not user_pain_df.empty:
                    combined_df = combined_df.join(user_pain_df[['pain_level']])
                
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸° (ê·¸ë˜í”„ í‘œì‹œìš©)
                combined_df = combined_df.fillna({'completed_count': 0, 'pain_level': 0})
                combined_df = combined_df.reset_index()
                combined_df = combined_df.rename(columns={'index': 'date'})
                
                # ë°ì´í„° ì •ë ¬
                combined_df = combined_df.sort_values('date')

                # ìš´ë™ ë°ì´í„°ì™€ í†µì¦ ë°ì´í„°ë¥¼ ë¶„ë¦¬ (ì‹¤ì œ ê¸°ë¡ëœ ë°ì´í„°ë§Œ)
                # ê°™ì€ ë‚ ì§œì˜ ë°ì´í„°ëŠ” í•©ê³„/í‰ê·  ì²˜ë¦¬
                if not user_exercise_df.empty:
                    exercise_temp = user_exercise_df.reset_index()
                    exercise_temp['date_only'] = exercise_temp['date'].dt.date
                    # ê°™ì€ ë‚  ìš´ë™ íšŸìˆ˜ëŠ” í•©ê³„
                    exercise_data = exercise_temp.groupby('date_only').agg({
                        'completed_count': 'sum',
                        'date': 'first'
                    }).reset_index(drop=True)
                else:
                    exercise_data = pd.DataFrame()
                
                if not user_pain_df.empty:
                    pain_temp = user_pain_df.reset_index()
                    pain_temp['date_only'] = pain_temp['date'].dt.date
                    # ê°™ì€ ë‚  í†µì¦ ì ìˆ˜ëŠ” í‰ê· 
                    pain_data = pain_temp.groupby('date_only').agg({
                        'pain_level': 'mean',
                        'date': 'first'
                    }).reset_index(drop=True)
                    # í‰ê· ì„ ì •ìˆ˜ë¡œ ë°˜ì˜¬ë¦¼
                    pain_data['pain_level'] = pain_data['pain_level'].round().astype(int)
                else:
                    pain_data = pd.DataFrame()
                
                # ì•ˆì „í•œ ìµœëŒ€ê°’ ê³„ì‚°
                max_count = max(exercise_data['completed_count'].max() if not exercise_data.empty else 1, 1)
                max_pain = max(pain_data['pain_level'].max() if not pain_data.empty else 1, 1)

                # ìš´ë™ íšŸìˆ˜ ì°¨íŠ¸ (ë°” ì°¨íŠ¸) - ê°œì„ ëœ ë²„ì „
                if not exercise_data.empty and len(exercise_data) > 0:
                    # ë°ì´í„° ì •ë¦¬
                    exercise_chart_data = exercise_data.copy()
                    exercise_chart_data['date'] = pd.to_datetime(exercise_chart_data['date'])
                    exercise_chart_data = exercise_chart_data.sort_values('date')
                    
                    bar_chart = alt.Chart(exercise_chart_data).mark_bar(
                        color='#26A69A', 
                        opacity=0.8,
                        cornerRadiusTopLeft=3,
                        cornerRadiusTopRight=3
                    ).encode(
                        x=alt.X('date:T', 
                               title='ë‚ ì§œ', 
                               axis=alt.Axis(format="%m/%d", labelAngle=-45, labelPadding=10)),
                        y=alt.Y('completed_count:Q',
                               title='ìš´ë™ ì™„ë£Œ íšŸìˆ˜',
                               scale=alt.Scale(domain=[0, max(exercise_chart_data['completed_count'].max() + 1, 5)])),
                        tooltip=['date:T', 'completed_count:Q']
                    ).properties(
                        title=f'ğŸ“Š ìš´ë™ ì™„ë£Œ íšŸìˆ˜ (ìµœê·¼ {exercise_chart_data["date"].dt.date.nunique()}ì¼)',
                        height=250
                    )
                    
                    st.altair_chart(bar_chart, use_container_width=True)
                else:
                    st.info("ğŸ“ˆ ìš´ë™ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. ìš´ë™ì„ ì™„ë£Œí•˜ë©´ ì°¨íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

                # í†µì¦ ì ìˆ˜ ì°¨íŠ¸ (ì„  + ì  ì°¨íŠ¸) - ê°œì„ ëœ ë²„ì „  
                if not pain_data.empty and len(pain_data) > 0:
                    # ë°ì´í„° ì •ë¦¬
                    pain_chart_data = pain_data.copy()
                    pain_chart_data['date'] = pd.to_datetime(pain_chart_data['date'])
                    pain_chart_data = pain_chart_data.sort_values('date')
                    
                    line_chart = alt.Chart(pain_chart_data).mark_line(
                        color='#FF5722', 
                        strokeWidth=3,
                        point=alt.OverlayMarkDef(color='#FF5722', size=100)
                    ).encode(
                        x=alt.X('date:T', 
                               title='ë‚ ì§œ',
                               axis=alt.Axis(format="%m/%d", labelAngle=-45, labelPadding=10)),
                        y=alt.Y('pain_level:Q',
                               title='í†µì¦ ì ìˆ˜ (0-15)',
                               scale=alt.Scale(domain=[0, 15])),
                        tooltip=['date:T', 'pain_level:Q']
                    ).properties(
                        title=f'ğŸ“‰ í†µì¦ ì ìˆ˜ ë³€í™” (ìµœê·¼ {pain_chart_data["date"].dt.date.nunique()}ì¼)',
                        height=250
                    )
                    
                    st.altair_chart(line_chart, use_container_width=True)
                else:
                    st.info("ğŸ“‰ í†µì¦ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤. í†µì¦ì„ ê¸°ë¡í•˜ë©´ ì°¨íŠ¸ê°€ í‘œì‹œë©ë‹ˆë‹¤.")
                
                # ë°ì´í„° ìš”ì•½ í‘œì‹œ
                st.subheader("ğŸ“Š ë°ì´í„° ìš”ì•½")
                col1, col2 = st.columns(2)
                with col1:
                    if not exercise_data.empty:
                        unique_exercise_days = exercise_data['date'].dt.date.nunique()
                        st.metric("ìš´ë™í•œ ë‚ ", f"{unique_exercise_days}ì¼")
                        st.metric("ì´ ìš´ë™ íšŸìˆ˜", f"{int(exercise_data['completed_count'].sum())}íšŒ")
                        st.metric("í‰ê·  ìš´ë™ íšŸìˆ˜", f"{exercise_data['completed_count'].mean():.1f}íšŒ/ì¼")
                with col2:
                    if not pain_data.empty:
                        unique_pain_days = pain_data['date'].dt.date.nunique()
                        st.metric("ê¸°ë¡í•œ ë‚ ", f"{unique_pain_days}ì¼")
                        st.metric("í‰ê·  í†µì¦ ì ìˆ˜", f"{pain_data['pain_level'].mean():.1f}/15")
                        st.metric("ìµœê³  í†µì¦ ì ìˆ˜", f"{int(pain_data['pain_level'].max())}/15")
            else:
                st.info("í˜„ì¬ ì‚¬ìš©ìì˜ ìš´ë™/í†µì¦ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ì°¨íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            st.info("ê¸°ë³¸ ì°¨íŠ¸ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")
            
            # ì•ˆì „í•œ ê¸°ë³¸ ì°¨íŠ¸ í‘œì‹œ
            try:
                # ê¸°ë³¸ ë°ì´í„°í”„ë ˆì„ ìƒì„± (pain_level ì»¬ëŸ¼ í¬í•¨)
                if pain_df.empty or 'pain_level' not in pain_df.columns:
                    pain_df = pd.DataFrame({
                        'user_id': [user_id],
                        'date': [pd.to_datetime(today)],
                        'pain_level': [0]
                    })
                
                if exercise_df.empty or 'completed_count' not in exercise_df.columns:
                    exercise_df = pd.DataFrame({
                        'user_id': [user_id],
                        'date': [pd.to_datetime(today)],
                        'completed_count': [0]
                    })
                
                # ê¸°ë³¸ ì°¨íŠ¸ í‘œì‹œ
                basic_df = pd.DataFrame({
                    'date': [today],
                    'completed_count': [exercise_df['completed_count'].sum() if not exercise_df.empty else 0],
                    'pain_level': [pain_df['pain_level'].mean() if not pain_df.empty else 0]
                })
                
                # ê¸°ë³¸ ì°¨íŠ¸ ìƒì„± (íŒ¨ë”© ë° ë ˆì´ë¸” ê°ë„ ì ìš©)
                bar_chart = alt.Chart(basic_df).mark_bar(color='#26A69A').encode(
                    x=alt.X('date:T', title='ë‚ ì§œ', axis=alt.Axis(labelAngle=-45)),
                    y=alt.Y('completed_count:Q', title='ìš´ë™ íšŸìˆ˜', scale=alt.Scale(domain=[0, 10]), axis=alt.Axis(titlePadding=20))
                )
                
                line_chart = alt.Chart(basic_df).mark_line(color='#FF5722').encode(
                    x=alt.X('date:T', title='ë‚ ì§œ', axis=alt.Axis(labelAngle=-45)),
                    y=alt.Y('pain_level:Q', title='í†µì¦ ì ìˆ˜', scale=alt.Scale(domain=[0, 15]), axis=alt.Axis(titlePadding=20))
                )
                
                combined_chart = alt.layer(bar_chart, line_chart).resolve_scale(y='independent').properties(
                    padding={'left': 80, 'right': 80, 'top': 40, 'bottom': 80}
                )
                st.altair_chart(combined_chart, use_container_width=True)
                
            except Exception as fallback_error:
                st.warning(f"ê¸°ë³¸ ì°¨íŠ¸ë„ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {fallback_error}")
                st.info("ë°ì´í„°ë¥¼ ê¸°ë¡í•œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

    else:
        st.info("ìš´ë™ ê¸°ë¡ ë° í†µì¦ ê¸°ë¡ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ë£¨í‹´ì„ ì™„ë£Œí•˜ê³  í†µì¦ì„ ê¸°ë¡í•´ ë³´ì„¸ìš”.")
        
        # ê¸°ë³¸ ê·¸ë˜í”„ í‘œì‹œ (ë°ì´í„°ê°€ ì—†ì–´ë„)
        st.subheader("ğŸ“Š ì˜¤ëŠ˜ì˜ ê¸°ë¡")
        today = date.today()
        
        # ê¸°ë³¸ ë°ì´í„° ìƒì„±
        basic_df = pd.DataFrame({
            'date': [today],
            'completed_count': [0],
            'pain_level': [0]
        })
        
        # Altairë¥¼ ì‚¬ìš©í•œ ì´ì¤‘ ì¶• ì°¨íŠ¸ ìƒì„± (ë‚ ì§œ ë ˆì´ë¸” ê°ë„ ì¶”ê°€)
        base = alt.Chart(basic_df).encode(
            alt.X('date:T', title='ë‚ ì§œ', axis=alt.Axis(labelAngle=-45))
        )
        
        bar_chart = base.mark_bar(color='#26A69A').encode(
            y=alt.Y(
                'completed_count:Q',
                title='ìš´ë™ íšŸìˆ˜',
                axis=alt.Axis(labels=True, titleColor='#26A69A', titlePadding=20),
                scale=alt.Scale(domain=[0, 10])
            )
        )
        
        line_chart = base.mark_line(color='#FF5722').encode(
            y=alt.Y(
                'pain_level:Q',
                title='í†µì¦ ì ìˆ˜',
                axis=alt.Axis(labels=True, titleColor='#FF5722'),
                scale=alt.Scale(domain=[0, 15])
            )
        )
        
        point_chart = base.mark_point(
            color='#FF5722',
            size=100,
            filled=True,
        ).encode(
            y=alt.Y(
                'pain_level:Q',
                title='í†µì¦ ì ìˆ˜',
                axis=alt.Axis(labels=True, titleColor='#FF5722'),
                scale=alt.Scale(domain=[0, 15])
            ),
            tooltip=[
                alt.Tooltip('date:T', title='ë‚ ì§œ'),
                alt.Tooltip('pain_level:Q', title='í†µì¦ ì ìˆ˜')
            ]
        )
        
        combined_chart = alt.layer(bar_chart, line_chart, point_chart).resolve_scale(
            y='independent'
        ).properties(
            title='ìš´ë™ íšŸìˆ˜ì™€ í†µì¦ ì ìˆ˜ ë³€í™” (ê¸°ë³¸ í‘œì‹œ)',
            padding={'left': 80, 'right': 80, 'top': 40, 'bottom': 80}
        )
        
        st.altair_chart(combined_chart, use_container_width=True)
        st.info("ğŸ’¡ ìš´ë™ì„ ì™„ë£Œí•˜ê³  í†µì¦ì„ ê¸°ë¡í•˜ë©´ ê·¸ë˜í”„ê°€ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤!")
        
        st.markdown("---")

# App Main Entry Point
if __name__ == "__main__":
    # ê°œì¸ì •ë³´ ì…ë ¥ì—ì„œ ì„¤ì •ëœ ì´ë©”ì¼ ì‚¬ìš©
    user_email = st.session_state.user_data.get('email', '') if hasattr(st.session_state, 'user_data') else ''
    show_integrated_dashboard(user_email)
